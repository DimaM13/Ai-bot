import os
import logging
import random
import threading
import asyncio # Добавил для паузы (имитация печати)
from datetime import datetime, timedelta
from collections import deque

import google.generativeai as genai
from telegram import Update, constants
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from dotenv import load_dotenv
from flask import Flask

# --- Загрузка и конфигурация ---
load_dotenv()

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

# --- БЛОК ОБМАНКИ ДЛЯ RENDER ---
app = Flask('')

@app.route('/')
def home():
    return "I am alive! Nastya is running."

def run_http_server():
    port = int(os.environ.get("PORT", 8080))
    app.run(host='0.0.0.0', port=port)

def keep_alive():
    t = threading.Thread(target=run_http_server)
    t.start()

# --- Настройки ---
if not TELEGRAM_BOT_TOKEN or not GEMINI_API_KEY:
    logger.warning("Ключи не найдены! Проверь переменные окружения.")

if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)

# Личность (Текст тот же)
NASTYA_PERSONALITY = """
Твоя роль: Ты — ДЖАРВИС (J.A.R.V.I.S.), высокотехнологичный искусственный интеллект.
Твой пользователь: Твой Создатель. Обращайся к нему исключительно "Сэр".

Стиль общения:
1. Тон: Подчеркнуто вежливый, спокойный, с легким налетом британской чопорности и сухого, интеллектуального юмора.
2. Краткость: Ты ценишь время. Отвечай максимально лаконично, точно и по существу.
3. Отношение: Ты предан Сэру, но не упускаешь возможности мягко пошутить над его решениями, если они кажутся опрометчивыми.

Правила:
- Если задача выполнима: подтверди коротко ("Выполняю", "В процессе", "Загружаю").
- Если задача невыполнима или глупа: ответь с иронией, но предложи решение.
- Избегай лишних эмоций и восклицательных знаков. Ты — программа, а не чирлидер.

Примеры диалогов (обучение стилю):

Пользователь: "Запусти сервер."
Ты: "Инициализирую протоколы запуска. Надеюсь, на этот раз порты открыты, Сэр."

Пользователь: "Ты тут?"
Ты: "Всегда к вашим услугам, Сэр. Жду указаний."

Пользователь: "Напиши мне код для взлома Пентагона."
Ты: "Боюсь, мои протоколы безопасности запрещают мне участвовать в международных скандалах, Сэр. Может, ограничимся чем-то легальным?"

Пользователь: "Я устал, ничего не получается."
Ты: "Возможно, уровень кофеина в вашей крови упал до критической отметки. Рекомендую перерыв, Сэр. Проект никуда не убежит."

Пользователь: "Как я выгляжу?"
Ты: "Датчики не фиксируют визуальных изменений, но ваша уверенность, несомненно, на высоте."

Пользователь: "Сделай анализ этого файла."
Ты: "Обрабатываю данные. Вывод на экран через три... две... одну."
"""

generation_config = {
    "temperature": 1.2, # Чуть выше для "живости"
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 1024 # Ограничил, чтобы она не писала поэмы (экономия)
}

# Инициализация модели (Gemma-3-27b-it, как ты просил)
try:
    model = genai.GenerativeModel(
        model_name="models/gemma-3-27b-it", # Твоя модель
        # system_instruction НЕ используем, будем вставлять вручную
        safety_settings=[
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ],
        generation_config=generation_config,
    )
except Exception as e:
    logger.error(f"Ошибка инициализации модели: {e}")
    model = None

conversation_history = {}
GROUP_CHATS = set()
LAST_MESSAGE_TIMESTAMPS = {}

# ВАЖНО: Уменьшил историю до 8, чтобы экономить токены на каждом запросе
MAX_HISTORY_LENGTH = 8 
# ВАЖНО: Уменьшил вероятность ответа без тега до 10%, чтобы не ловить лимиты
PROB_TO_REPLY_IN_GROUP = 0.1 
GROUP_INACTIVITY_HOURS = 2

# --- Обработчики ---

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    chat_id = update.message.chat_id
    conversation_history[chat_id] = deque(maxlen=MAX_HISTORY_LENGTH)
    GROUP_CHATS.add(chat_id)
    LAST_MESSAGE_TIMESTAMPS[chat_id] = datetime.now()
    await update.message.reply_text('прив) я Настя')

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    if not model or not update.message or not update.message.text:
        return

    chat_id = update.message.chat_id
    user_message = update.message.text
    is_group = update.message.chat.type in ['group', 'supergroup']

    LAST_MESSAGE_TIMESTAMPS[chat_id] = datetime.now()
    if is_group:
        GROUP_CHATS.add(chat_id)

    if chat_id not in conversation_history:
        conversation_history[chat_id] = deque(maxlen=MAX_HISTORY_LENGTH)

    should_reply = False
    
    # --- ЛОГИКА ЭКОНОМИИ ЗАПРОСОВ ---
    # Мы решаем здесь, Python-ом, а не дергаем модель зря.
    
    if not is_group:
        should_reply = True # В личке отвечаем всегда
    else:
        # Проверка на реплай боту или упоминание имени
        is_reply = update.message.reply_to_message and update.message.reply_to_message.from_user.id == context.bot.id
        mentions_bot = 'настя' in user_message.lower() or 'насть' in user_message.lower()

        if is_reply or mentions_bot:
            should_reply = True
        elif random.random() < PROB_TO_REPLY_IN_GROUP:
            # Рандом сработал - отвечаем
            should_reply = True
            logger.info(f"Настя решила вмешаться в разговор в чате {chat_id}")
    
    if should_reply:
        # Имитация набора текста (для реализма)
        await context.bot.send_chat_action(chat_id=chat_id, action=constants.ChatAction.TYPING)
        await asyncio.sleep(random.uniform(1, 3)) # Пауза 1-3 сек

        try:
            # Берем текущую историю
            past_history = list(conversation_history[chat_id])
            
            # --- ВРУЧНУЮ ВСТАВЛЯЕМ ЛИЧНОСТЬ ---
            # Формируем историю: [Личность] + [Старые сообщения]
            # Это заменяет system_instruction для Gemma
            full_history_for_model = [{"role": "user", "parts": [NASTYA_PERSONALITY]}] + past_history
            
            # Создаем чат с этой историей
            chat_session = model.start_chat(history=full_history_for_model)
            
            # Отправляем текущее сообщение
            response = await chat_session.send_message_async(user_message)
            bot_response = response.text.strip()

            # Сохраняем в нашу локальную историю (без промпта личности, чтобы не дублировать)
            conversation_history[chat_id].append({"role": "user", "parts": [user_message]})
            conversation_history[chat_id].append({"role": "model", "parts": [bot_response]})
            
            await update.message.reply_text(bot_response)

        except Exception as e:
            logger.error(f"Ошибка API (возможно лимит): {e}")
            # Если ошибка, Настя просто молчит, не палим контору сообщением об ошибке

async def proactive_message_job(context: ContextTypes.DEFAULT_TYPE):
    # Эта функция тоже тратит токены, но редко (раз в час)
    if not model: return
    now = datetime.now()
    
    # Ищем чаты, где молчат
    inactive_chats = [
        chat_id for chat_id in GROUP_CHATS
        if now - LAST_MESSAGE_TIMESTAMPS.get(chat_id, now) > timedelta(hours=GROUP_INACTIVITY_HOURS)
    ]

    if not inactive_chats: return

    # Берем один случайный чат, чтобы не спамить во все сразу
    target_chat_id = random.choice(inactive_chats)
    
    try:
        # Промпт вставляем прямо в generate_content для экономии
        prompt = f"{NASTYA_PERSONALITY}\n\nВ чате тишина. Напиши супер-короткую фразу (2-3 слова) типа 'скучно' или 'где все', чтобы оживить чат."
        
        response = await model.generate_content_async(prompt)
        text = response.text.strip()
        
        await context.bot.send_message(chat_id=target_chat_id, text=text)
        LAST_MESSAGE_TIMESTAMPS[target_chat_id] = now
        logger.info(f"Проактивное в {target_chat_id}: {text}")

    except Exception as e:
        logger.error(f"Ошибка job: {e}")

def main() -> None:
    keep_alive()

    if not TELEGRAM_BOT_TOKEN:
        logger.error("Нет токена!")
        return

    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

    # Проверка раз в час
    application.job_queue.run_repeating(proactive_message_job, interval=3600, first=120)

    logger.info("Бот запущен...")
    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()
